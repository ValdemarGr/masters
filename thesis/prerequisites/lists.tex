
\section{Lists and immutability}
An instance of a data structure which has been thoroughly discussed throughout this thesis is \texttt{List} (\autoref{lst:listadt}).
\texttt{List} is an excellent choice as an introductory data structure since it gives insight into some very universal problems regarding both immutable and mutable data structures.
One is free to choose the operations for \texttt{List} but a common operation is \texttt{map} (\autoref{lst:map}).
\begin{lstlisting}[language=ML,caption={Mapping from \texttt{List a} to \texttt{List b}},label={lst:map},mathescape=true]
fun map f l = 
   match l
    | Cons x xs -> Cons (f x) (map f xs);
    | Nil -> l;
   ;
\end{lstlisting}

There exists several analytical techniques to justify performance guarantees in data structures, the most straight forward of which is the worst case analysis.
Worst case analysis is usually the most straight forward, since it becomes a matter of finding the worst input for any possible state of the data structure.
The worst case analysis is often exactly the same for a call by need data structure as a call by value (given that it is the same underlying implementation).

An interesting observation from map is that it runs differently in a call by need environment compared to a call by value environment.
In a call by value environment the operation takes $\Theta(n)$ time since every \texttt{Cons}'ed value must be visited.
In a call by need environment things become a bit more philosophical.
When \texttt{map} is evaluated in a call by need environment it is technically suspended thus always requires one operation.
When a value which depends on a \texttt{map} invocation is forced (from the addition operator for instance), then the computational complexity has the same bounds as if it were call by value.
The computational complexity in a call by need (or name) environment is thus $O(n)$ and $\Omega(1)$, in general \textit{all} call by need algorithms run in $\Omega(1)$.
